{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries needed\n",
    "import os\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Activation,Flatten,Dropout\n",
    "from tensorflow.keras.layers import Conv2D,MaxPooling2D, AveragePooling2D\n",
    "\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n",
    "\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = ImageDataGenerator(rotation_range=20,\n",
    "                            zoom_range=0.15,\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            shear_range=0.15,\n",
    "                            horizontal_flip=True,\n",
    "                            validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = 'Dataset/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 22048 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "training_data = train.flow_from_directory(train_path,\n",
    "                                          target_size=(224, 224),\n",
    "                                          class_mode='categorical',\n",
    "                                          subset=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5510 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_data = train.flow_from_directory(train_path,\n",
    "                                          target_size=(224, 224),\n",
    "                                          class_mode='categorical',                                          \n",
    "                                          subset=\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Parasitized': 0, 'Uninfected': 1}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the MobileNetV2 network, ensuring the head FC layer sets are left off\n",
    "Head = MobileNetV2(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in Head.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.add(\n",
    "    Head\n",
    ")\n",
    "\n",
    "base.add(\n",
    "    AveragePooling2D(pool_size=(7,7))\n",
    ")\n",
    "\n",
    "base.add(\n",
    "    Flatten()\n",
    ")\n",
    "\n",
    "base.add(\n",
    "    Dense(128, activation=\"relu\")\n",
    ")\n",
    "\n",
    "base.add(\n",
    "    Dropout(0.5)\n",
    ")\n",
    "\n",
    "base.add(\n",
    "    Dense(2, activation=\"softmax\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "base.compile(loss=\"categorical_crossentropy\", \n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/akshit_venv/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "689/689 [==============================] - 1091s 2s/step - loss: 0.6873 - accuracy: 0.6321 - val_loss: 0.5135 - val_accuracy: 0.7439\n",
      "Epoch 2/10\n",
      "689/689 [==============================] - 1045s 2s/step - loss: 0.5277 - accuracy: 0.7368 - val_loss: 0.4868 - val_accuracy: 0.7713\n",
      "Epoch 3/10\n",
      "689/689 [==============================] - 1042s 2s/step - loss: 0.5066 - accuracy: 0.7523 - val_loss: 0.4678 - val_accuracy: 0.7780\n",
      "Epoch 4/10\n",
      "689/689 [==============================] - 1047s 2s/step - loss: 0.4946 - accuracy: 0.7542 - val_loss: 0.4606 - val_accuracy: 0.7735\n",
      "Epoch 5/10\n",
      "689/689 [==============================] - 1052s 2s/step - loss: 0.4880 - accuracy: 0.7588 - val_loss: 0.4500 - val_accuracy: 0.7864\n",
      "Epoch 6/10\n",
      "689/689 [==============================] - 1075s 2s/step - loss: 0.4874 - accuracy: 0.7608 - val_loss: 0.4642 - val_accuracy: 0.7927\n",
      "Epoch 7/10\n",
      "689/689 [==============================] - 1050s 2s/step - loss: 0.4826 - accuracy: 0.7688 - val_loss: 0.4434 - val_accuracy: 0.7851\n",
      "Epoch 8/10\n",
      "689/689 [==============================] - 1056s 2s/step - loss: 0.4779 - accuracy: 0.7703 - val_loss: 0.4580 - val_accuracy: 0.7779\n",
      "Epoch 9/10\n",
      "689/689 [==============================] - 1064s 2s/step - loss: 0.4738 - accuracy: 0.7728 - val_loss: 0.4413 - val_accuracy: 0.7929\n",
      "Epoch 10/10\n",
      "689/689 [==============================] - 1054s 2s/step - loss: 0.4711 - accuracy: 0.7720 - val_loss: 0.4308 - val_accuracy: 0.7933\n"
     ]
    }
   ],
   "source": [
    "history = base.fit_generator(training_data,\n",
    "                             epochs=10,\n",
    "                             validation_data=validation_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
