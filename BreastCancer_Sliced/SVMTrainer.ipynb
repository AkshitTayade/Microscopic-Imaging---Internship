{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataLoader:\n",
    "    def __init__(self,datasetPath,batch,imageSegmentNo) -> None:\n",
    "        self.datasetPath = datasetPath\n",
    "        \n",
    "        self.batchPath = f'{datasetPath}/{batch}'\n",
    "        self.classes = os.listdir(self.batchPath)\n",
    "\n",
    "\n",
    "        self.imageSegmentNo = imageSegmentNo\n",
    "\n",
    "        self.scaledData = []\n",
    "        \n",
    "\n",
    "        self.dataExtractor()\n",
    "        self.shuffler()\n",
    "        \n",
    "\n",
    "    def dataExtractor(self):\n",
    "        for i in range(len(self.classes)):\n",
    "            if len(self.classes[i].split('.'))<=1:\n",
    "\n",
    "                for imgdir in os.listdir(f'{self.batchPath}/{self.classes[i]}'):\n",
    "                    if len(imgdir.split('.'))<=1:\n",
    "                        jsonMetadata = self.jsonDataLoader(f'{self.batchPath}/{self.classes[i]}/{imgdir}/metadata.json')\n",
    "                        \n",
    "\n",
    "                        self.scaledData.append([  self.featureScaler(jsonMetadata['features'][self.imageSegmentNo]), jsonMetadata['classes'][self.imageSegmentNo]])\n",
    "                        # self.y.append()\n",
    "\n",
    "\n",
    "                        \n",
    "\n",
    "\n",
    "    def jsonDataLoader(self,jsonPath):\n",
    "        with open(jsonPath) as jsonfile:\n",
    "            currentData = json.load(jsonfile)\n",
    "            return currentData\n",
    "\n",
    "    def featureScaler(self,feature):\n",
    "\n",
    "        maxVal = max(feature[0])\n",
    "        minVal = min(feature[0])\n",
    "\n",
    "        dezmin = 0\n",
    "        dezmax = 1\n",
    "\n",
    "        scaledFeatures =  []\n",
    "        for i in feature[0]:\n",
    "            scaled = (    (   (i - minVal)/(maxVal-minVal)  ) /   (dezmax-dezmin)    ) + dezmin\n",
    "            scaledFeatures.append(scaled)\n",
    "\n",
    "        return np.array(scaledFeatures)\n",
    "\n",
    "\n",
    "    def shuffler(self):\n",
    "        valData=  np.array(self.scaledData)\n",
    "        np.random.shuffle(valData)\n",
    "        \n",
    "        ListX = []\n",
    "        Listy = []\n",
    "\n",
    "\n",
    "        for i in valData:\n",
    "            ListX.append(i[0])\n",
    "            Listy.append(i[1])\n",
    "\n",
    "        self.X = np.array(ListX)\n",
    "        self.y = np.array(Listy)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4m/_7y4kbtd0l5gjj3fhdysn97c0000gn/T/ipykernel_20966/3157486618.py:56: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  valData=  np.array(self.scaledData)\n"
     ]
    }
   ],
   "source": [
    "valDataComplete = []\n",
    "for i in range(9):\n",
    "    valDataComplete.append(DataLoader('All_200X','val',i))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4m/_7y4kbtd0l5gjj3fhdysn97c0000gn/T/ipykernel_20966/3157486618.py:56: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  valData=  np.array(self.scaledData)\n"
     ]
    }
   ],
   "source": [
    "trainDataComplete = []\n",
    "for i in range(9):\n",
    "    trainDataComplete.append(DataLoader('All_200X','train',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4m/_7y4kbtd0l5gjj3fhdysn97c0000gn/T/ipykernel_20966/3157486618.py:56: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  valData=  np.array(self.scaledData)\n"
     ]
    }
   ],
   "source": [
    "testDataComplete = []\n",
    "for i in range(9):\n",
    "    testDataComplete.append(DataLoader('All_200X','test',i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class multiSVM:\n",
    "    def __init__(self,traindata,testdata) -> None:\n",
    "        self.clfs = []\n",
    "        self.traindata = traindata\n",
    "        self.testdata = testdata\n",
    "        self.scores = []\n",
    "\n",
    "    def modelCreator(self):\n",
    "        for i in range(9):\n",
    "            self.clfs.append(SVC(kernel='rbf', C=1).fit(self.traindata[i].X,self.traindata[i].y))\n",
    "    \n",
    "    def estimator(self):\n",
    "        for i in range(9):\n",
    "            y_preds = self.clfs[i].predict(self.testdata[i].X)\n",
    "            self.scores.append(accuracy_score(self.testdata[i].y,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8360655737704918, 0.8426229508196721, 0.8426229508196721, 0.8557377049180328, 0.8360655737704918, 0.8557377049180328, 0.8426229508196721, 0.8327868852459016, 0.8426229508196721]\n"
     ]
    }
   ],
   "source": [
    "ensembleSVMs = multiSVM(trainDataComplete,testDataComplete)\n",
    "ensembleSVMs.modelCreator()\n",
    "ensembleSVMs.estimator()\n",
    "print(ensembleSVMs.scores)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "59a0a655608065d3cae818a692331e53ebb08743a1f5b6e8817ade25a17588c1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit ('tfworking': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
